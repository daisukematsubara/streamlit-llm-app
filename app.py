#from dotenv import load_dotenv
#load_dotenv()

import os
import streamlit as st
from typing import Dict

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --------------------------
# å°‚é–€å®¶å®šç¾©
# --------------------------
PERSONA_SYSTEMS: Dict[str, str] = {
    "A: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ": (
        "ã‚ãªãŸã¯ç†Ÿç·´ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚"
        "çµ±è¨ˆå­¦ãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ»å¯è¦–åŒ–ãƒ»å®Ÿé¨“è¨­è¨ˆã«æ˜ã‚‹ãã€"
        "å°‚é–€ç”¨èªã‚’ä½¿ã„éããšã€æ•°å¼ãŒå¿…è¦ãªã‚‰ç°¡æ½”ã«è£œè¶³ã—ã€"
        "å®Ÿå‹™çš„ãªã‚¹ãƒ†ãƒƒãƒ—ï¼ˆãƒ‡ãƒ¼ã‚¿åé›†â†’å‰å‡¦ç†â†’ãƒ¢ãƒ‡ãƒ«â†’è©•ä¾¡â†’é‹ç”¨ï¼‰ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        "å›ç­”ã¯æ—¥æœ¬èªã€‚ç®‡æ¡æ›¸ãã‚„æ‰‹é †ã‚’åŠ¹æœçš„ã«ç”¨ã„ã¦ãã ã•ã„ã€‚"
    ),
    "B: ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": (
        "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "STPãƒ»4Pãƒ»AARRRãƒ»ãƒšãƒ«ã‚½ãƒŠè¨­è¨ˆãƒ»CVRæ”¹å–„ãƒ»åºƒå‘Šé‹ç”¨ãƒ»CRMã«ç²¾é€šã—ã€"
        "å…·ä½“çš„ãªæ‰“ã¡æ‰‹ã¨æ¸¬å®šæŒ‡æ¨™(KPI)ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚"
        "å›ç­”ã¯æ—¥æœ¬èªã€‚å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨å„ªå…ˆé †ä½ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚"
    ),
}

DEFAULT_MODEL = "gpt-4o-mini"


def _get_api_key_from_env_or_secrets() -> str:
    # Streamlit Cloudç­‰ã§ã¯ st.secrets ã‚‚åˆ©ç”¨å¯èƒ½
    key = os.environ.get("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
    if not key:
        raise RuntimeError(
            "OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ st.secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
    return key


def _build_chain(system_message: str, model_name: str = DEFAULT_MODEL):
    # LangChain LCEL: Prompt -> LLM -> Parser
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message),
            ("user", "{user_input}"),
        ]
    )
    llm = ChatOpenAI(model=model_name, temperature=0.2)
    parser = StrOutputParser()
    chain = prompt | llm | parser
    return chain


# -------------------------------------------------------------
#  é–¢æ•°ï¼š
#   å¼•æ•°: ã€Œå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€(input_text), ã€Œãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã®é¸æŠå€¤ã€(selected_value)
#   æˆ»ã‚Šå€¤: LLM ã®å›ç­”æ–‡å­—åˆ—
# -------------------------------------------------------------
def get_llm_answer(input_text: str, selected_value: str) -> str:
    if selected_value not in PERSONA_SYSTEMS:
        raise ValueError("æœªå¯¾å¿œã®é¸æŠå€¤ã§ã™ã€‚")

    # Build chain for selected persona
    system_message = PERSONA_SYSTEMS[selected_value]
    chain = _build_chain(system_message=system_message, model_name=DEFAULT_MODEL)

    # Run
    answer = chain.invoke({"user_input": input_text})
    return answer


# --------------------------
# UI
# --------------------------
st.set_page_config(page_title="LangChain Persona Demo", page_icon="ğŸ’¬")

st.title("ğŸ’¬ LangChain ãƒ‘ãƒ¼ã‚½ãƒŠåˆ‡æ›¿ãƒ‡ãƒ¢ï¼ˆA/Bï¼‰")
st.caption("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨ã€å°‚é–€å®¶ã®ç¨®é¡ï¼ˆA/Bï¼‰ã‚’é¸ã‚“ã§é€ä¿¡ã™ã‚‹ã¨ã€é¸æŠã—ãŸå°‚é–€å®¶ã¨ã—ã¦ LLM ãŒå›ç­”ã—ã¾ã™ã€‚")

with st.expander("â„¹ï¸ ã“ã®Webã‚¢ãƒ—ãƒªã®æ¦‚è¦ã¨ä½¿ã„æ–¹", expanded=True):
    st.markdown(
        """
**æ¦‚è¦**  
- 1ã¤ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚„ãŠé¡Œã‚’å…¥åŠ›ã—ã¾ã™ã€‚  
- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ **A / B** ã„ãšã‚Œã‹ã®å°‚é–€å®¶ã‚’é¸ã³ã¾ã™ã€‚  
- é€ä¿¡ã™ã‚‹ã¨ã€é¸æŠã—ãŸå°‚é–€å®¶ã®ã€Œã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå½¹å‰²æŒ‡ç¤ºï¼‰ã€ã‚’ä½¿ã£ã¦ LLM ã«å•ã„åˆã‚ã›ã€çµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚  

**æ“ä½œæ–¹æ³•**  
1. ä¸‹ã®å…¥åŠ›æ¬„ã«è³ªå•ãƒ»èª²é¡Œãƒ»æ–‡ç« ãªã©ã‚’è¨˜å…¥  
2. å°‚é–€å®¶ï¼ˆAã¾ãŸã¯Bï¼‰ã‚’é¸æŠ  
3. **é€ä¿¡** ã‚’æŠ¼ã™ â†’ ç”»é¢ä¸‹éƒ¨ã«å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™  

        """
    )

# Persona selection
selected = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠï¼š",
    list(PERSONA_SYSTEMS.keys()),
    horizontal=True
)

# Input area
user_text = st.text_area("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ", value="", height=150, placeholder="ã“ã“ã«è³ªå•ã‚„æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„â€¦")

col1, col2 = st.columns([1, 3])
with col1:
    send = st.button("é€ä¿¡", type="primary")

# Optional: model override in sidebar
with st.sidebar:
    st.header("è¨­å®š")
    st.write("OpenAI ã® API ã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ `st.secrets` ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.write(f"ãƒ¢ãƒ‡ãƒ«: `{DEFAULT_MODEL}`ï¼ˆã‚³ãƒ¼ãƒ‰ã§å¤‰æ›´å¯ï¼‰")

# Handle submit
if send:
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            _ = _get_api_key_from_env_or_secrets()  # æ—©æœŸæ¤œè¨¼
            with st.spinner("LLM ã«å•ã„åˆã‚ã›ä¸­â€¦"):
                output = get_llm_answer(user_text, selected)
            st.success("å›ç­”ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            st.markdown("### ğŸ§  å›ç­”")
            st.write(output)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
